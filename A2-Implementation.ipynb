{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bfaef52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T19:31:14.473999Z",
     "iopub.status.busy": "2025-04-11T19:31:14.473400Z",
     "iopub.status.idle": "2025-04-11T19:31:14.477157Z",
     "shell.execute_reply": "2025-04-11T19:31:14.476474Z"
    },
    "papermill": {
     "duration": 0.007687,
     "end_time": "2025-04-11T19:31:14.478152",
     "exception": false,
     "start_time": "2025-04-11T19:31:14.470465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc266ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T19:31:14.482256Z",
     "iopub.status.busy": "2025-04-11T19:31:14.482071Z",
     "iopub.status.idle": "2025-04-11T19:31:14.485005Z",
     "shell.execute_reply": "2025-04-11T19:31:14.484290Z"
    },
    "papermill": {
     "duration": 0.00606,
     "end_time": "2025-04-11T19:31:14.486107",
     "exception": false,
     "start_time": "2025-04-11T19:31:14.480047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade -q wandb\n",
    "#!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe80e4b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T19:31:14.489985Z",
     "iopub.status.busy": "2025-04-11T19:31:14.489783Z",
     "iopub.status.idle": "2025-04-11T19:31:17.702338Z",
     "shell.execute_reply": "2025-04-11T19:31:17.701766Z"
    },
    "papermill": {
     "duration": 3.215651,
     "end_time": "2025-04-11T19:31:17.703425",
     "exception": false,
     "start_time": "2025-04-11T19:31:14.487774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmegh_m\u001b[0m (\u001b[33mmegh_m-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key = \"eb9574fa5b11da36782604ea27df8bf1989ddefd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b48338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T19:31:17.708721Z",
     "iopub.status.busy": "2025-04-11T19:31:17.708236Z",
     "iopub.status.idle": "2025-04-11T19:31:17.711001Z",
     "shell.execute_reply": "2025-04-11T19:31:17.710518Z"
    },
    "papermill": {
     "duration": 0.006374,
     "end_time": "2025-04-11T19:31:17.712007",
     "exception": false,
     "start_time": "2025-04-11T19:31:17.705633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pytorch-lightning torchvision\n",
    "#!pip install torch-lr-finder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c079f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T19:31:17.716451Z",
     "iopub.status.busy": "2025-04-11T19:31:17.716286Z",
     "iopub.status.idle": "2025-04-11T19:31:17.719663Z",
     "shell.execute_reply": "2025-04-11T19:31:17.719168Z"
    },
    "papermill": {
     "duration": 0.006774,
     "end_time": "2025-04-11T19:31:17.720678",
     "exception": false,
     "start_time": "2025-04-11T19:31:17.713904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_SILENT\"] = \"false\"\n",
    "os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"eb9574fa5b11da36782604ea27df8bf1989ddefd\"  # Get from https://wandb.ai/authorize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b4bae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T19:31:17.725257Z",
     "iopub.status.busy": "2025-04-11T19:31:17.725089Z",
     "iopub.status.idle": "2025-04-11T19:31:41.055149Z",
     "shell.execute_reply": "2025-04-11T19:31:41.054277Z"
    },
    "papermill": {
     "duration": 23.334276,
     "end_time": "2025-04-11T19:31:41.056817",
     "exception": false,
     "start_time": "2025-04-11T19:31:17.722541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms #To manage dataset\n",
    "from torch.utils.data import DataLoader, Subset #To load and transform data\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger # As pytorch.lightning allows direct logging into wandb\n",
    "#from sklearn.model_selection import StratifiedShuffleSplit '''Check with TAs'''\n",
    "\n",
    "class CNN(pl.LightningModule):\n",
    "    def __init__(self,config):\n",
    "        super().__init__() #using LightningModule to assign hyperparams\n",
    "        self.save_hyperparameters(ignore=[\"config\"])\n",
    "        self.config = config\n",
    "\n",
    "        self.final_ch, self.final_size = self.calc_output_dim(config)\n",
    "\n",
    "        self.build_nn(config)\n",
    "    \n",
    "    def build_nn(self,config):\n",
    "        self.conv_blk = nn.ModuleList()\n",
    "        input_ch = 3 #RGB images\n",
    "        current_filters = config.filter_base #Filter Number & Strategies from sweep config\n",
    "        for i in range(5): #Create five consecutive convolution blocks with configurable strategies\n",
    "            self.conv_blk.append(\n",
    "                nn.Conv2d(input_ch, current_filters, kernel_size = config.filter_size, padding = config.filter_size//2) #Use filter size from sweep config, padding = floor(0.5*filter)\n",
    "            )\n",
    "            self.conv_blk.append(self.actv(config.conv_actv))\n",
    "            self.conv_blk.append(nn.MaxPool2d(kernel_size = config.pool_size))#, padding = config.pool_size//2))\n",
    "            #Define organization logic for filters in subsequent layers from sweep config metric filter_org\n",
    "            if config.filter_org == \"double\":\n",
    "                input_ch = current_filters\n",
    "                current_filters *= 2 #Double number of filters\n",
    "            elif config.filter_org == \"halve\":\n",
    "                input_ch = current_filters\n",
    "                current_filters = max(8, current_filters//2) #Ensuring a minimum of 8 filters\n",
    "            else: #No filter strategies\n",
    "                input_ch = current_filters\n",
    "          \n",
    "        self.dense = nn.Sequential(\n",
    "              nn.Linear(self.final_ch*self.final_size**2, config.dense_neurons),\n",
    "              self.actv(config.dense_actv),\n",
    "              nn.Dropout(config.dropout),\n",
    "              nn.Linear(config.dense_neurons, 10)\n",
    "          )\n",
    "\n",
    "    #Calculate what the dimensions for the dense layer inputs would turn out to be\n",
    "    def calc_output_dim(self,config):\n",
    "          with torch.no_grad():\n",
    "            dummy = torch.randn(1, 3, 224, 224)\n",
    "            input_ch = 3\n",
    "            current_filters = config.filter_base\n",
    "            spatial_size =224\n",
    "\n",
    "            for i in range(5):\n",
    "                conv = nn.Conv2d(\n",
    "                    input_ch, \n",
    "                    current_filters,\n",
    "                    kernel_size=config.filter_size,\n",
    "                    padding=config.filter_size//2\n",
    "                )\n",
    "                dummy = conv(dummy)\n",
    "                dummy = self.actv(config.conv_actv)(dummy)\n",
    "\n",
    "                dummy = F.max_pool2d(dummy, kernel_size = config.pool_size)\n",
    "                spatial_size = spatial_size // config.pool_size\n",
    "                #Error handling due to multiple errors lol\n",
    "                if spatial_size<1:\n",
    "                  raise ValueError(\n",
    "                      f\"Pool Size {config.pool_size} wrong for 5 convs\"\n",
    "                      f\"Max allowed: {224**(1/5):.0f}\"\n",
    "                  )\n",
    "\n",
    "                # Update filter organization\n",
    "                if config.filter_org == \"double\":\n",
    "                    input_ch = current_filters\n",
    "                    current_filters *= 2\n",
    "                elif config.filter_org == \"halve\":\n",
    "                    input_ch = current_filters\n",
    "                    current_filters = max(8, current_filters // 2)\n",
    "                else:\n",
    "                    input_ch = current_filters\n",
    "            print(dummy.shape[1], dummy.shape[2])        \n",
    "            return dummy.shape[1], dummy.shape[2]\n",
    "    def actv(self,name): #Choosing activation func\n",
    "        actv={\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"gelu\": nn.GELU(),\n",
    "            \"silu\": nn.SiLU(),\n",
    "            \"mish\": nn.Mish()\n",
    "        }\n",
    "        return actv[name.lower()]\n",
    "\n",
    "    def forward(self,x): #Explicit Lightning Module Method Forward\n",
    "        for layer in self.conv_blk:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.size(0), -1) #Flatten\n",
    "        return self.dense(x) #Invoke Dense layers\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"train_loss\",loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat,y)\n",
    "        acc = (y_hat.argmax(dim=1) == y).float().mean() #Mean fractional accuracy\n",
    "        self.log(\"val_loss\",loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "        return {\"val_loss\":loss, \"val_acc\":acc}\n",
    "\n",
    "    def configure_optimizers(self): #Another pl method. We use Adam optim\n",
    "        return torch.optim.Adam(self.parameters(), lr = self.config.eta) #have to use self.hparams ,if used, as referring config outside the __init__\n",
    "\n",
    "class DataManager(pl.LightningModule):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transform = self.tfms()\n",
    "\n",
    "    def tfms(self): #Preprocess input data. Add (Augment) data to make model robust\n",
    "        base_transform = [\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = [0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "        ]\n",
    "        if self.config.data_augmentation==True:\n",
    "            train_transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.ColorJitter(brightness = 0.2, contrast = 0.2, saturation = 0.2),\n",
    "                *base_transform\n",
    "            ])\n",
    "        else:\n",
    "            train_transform = transforms.Compose(base_transform)\n",
    "        \n",
    "        return {\n",
    "            \"train\": train_transform,\n",
    "            \"val\": transforms.Compose(base_transform),\n",
    "            \"test\": transforms.Compose(base_transform)\n",
    "        }\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        full_data = datasets.ImageFolder(root=\"/kaggle/input/inaturalist/inaturalist_12K/train\", transform=self.transform[\"train\"])\n",
    "        #Implementing a random 80-20 train-val split\n",
    "        idx = list(range(len(full_data)))\n",
    "        np.random.seed(42) \n",
    "        np.random.shuffle(idx)\n",
    "        size=len(full_data)\n",
    "        split = int(np.floor(0.8*size)) \n",
    "        train_idx = idx[:split]\n",
    "        val_idx = idx[split:]\n",
    "\n",
    "        self.train_dataset = Subset(full_data, train_idx)\n",
    "        self.val_dataset = Subset(full_data, val_idx)\n",
    "        self.test_dataset = datasets.ImageFolder(root = \"/kaggle/input/inaturalist/inaturalist_12K/val\", transform=self.transform[\"test\"] )\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size = self.config.batch_size, shuffle=True, num_workers = 3)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size = self.config.batch_size, shuffle=False, num_workers = 3)\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size = self.config.batch_size, shuffle=True, num_workers = 3)\n",
    "\n",
    "#Define Configuration for param sweep\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\":\"val_acc\", \"goal\":\"maximize\"},\n",
    "    \"parameters\":{\n",
    "        \"filter_base\":{\"values\":[32,64]},\n",
    "        \"filter_size\":{\"values\":[3,5,7]},\n",
    "        \"filter_org\":{\"values\":[\"same\",\"double\",\"halve\"]},\n",
    "        \"conv_actv\":{\"values\":[\"relu\",\"gelu\",\"silu\",\"mish\"]},\n",
    "        \"pool_size\":{\"values\":[2]},\n",
    "        \"dense_actv\":{\"values\":[\"relu\",\"gelu\"]},\n",
    "        \"dense_neurons\":{\"values\":[512,1024]},\n",
    "        \"data_augmentation\":{\"values\":[True,False]},\n",
    "        \"batch_norm\":{\"values\":[True,False]},\n",
    "        \"dropout\":{\"values\":[0.2,0.3]},\n",
    "        \"eta\":{\"min\":0.0001, \"max\":0.01},\n",
    "        \"batch_size\":{\"values\":[64,128]}\n",
    "    },\n",
    "    \"early_terminate\":{\n",
    "        \"type\":\"hyperband\",\n",
    "        \"min_iter\": 3,\n",
    "        \"eta\": 2\n",
    "    },\n",
    "    \"command\": [\n",
    "        \"python\",\n",
    "        \"-W\", \"ignore\",  # Disable warnings\n",
    "        \"-u\",  # Unbuffered output\n",
    "        \"${program}\"  # Required for Kaggle compatibility\n",
    "    ]\n",
    "}\n",
    "def train_sweep():\n",
    "  wandb.init(project=\"DA6401_A2\",settings=wandb.Settings(start_method=\"thread\",_disable_stats=True))\n",
    "  config = wandb.config\n",
    "  data_manager = DataManager(config)\n",
    "  model = CNN(config)\n",
    "  trainer = pl.Trainer(\n",
    "      max_epochs = 10,\n",
    "      logger = WandbLogger(),\n",
    "      accelerator = \"auto\",\n",
    "      enable_checkpointing = False,\n",
    "      deterministic = True\n",
    "  )\n",
    "  trainer.fit(model, datamodule=data_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce87e53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T19:31:41.062254Z",
     "iopub.status.busy": "2025-04-11T19:31:41.061872Z",
     "iopub.status.idle": "2025-04-11T19:31:41.065119Z",
     "shell.execute_reply": "2025-04-11T19:31:41.064610Z"
    },
    "papermill": {
     "duration": 0.006877,
     "end_time": "2025-04-11T19:31:41.066164",
     "exception": false,
     "start_time": "2025-04-11T19:31:41.059287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sweep_id = wandb.sweep(sweep_config, project = \"DA6401_A2\")\n",
    "#wandb.agent(sweep_id, function=train_sweep, count = 10)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7065602,
     "sourceId": 11298830,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.835104,
   "end_time": "2025-04-11T19:31:44.495669",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-11T19:31:08.660565",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
