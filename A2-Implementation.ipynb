{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfaad2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:57:25.916187Z",
     "iopub.status.busy": "2025-04-11T14:57:25.915789Z",
     "iopub.status.idle": "2025-04-11T14:57:30.967302Z",
     "shell.execute_reply": "2025-04-11T14:57:30.966285Z"
    },
    "papermill": {
     "duration": 5.057676,
     "end_time": "2025-04-11T14:57:30.969196",
     "exception": false,
     "start_time": "2025-04-11T14:57:25.911520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "train_data = DataLoader(\"/kaggle/input/inaturalist/inaturalist_12K/train\")\n",
    "val_data = DataLoader(\"/kaggle/input/inaturalist/inaturalist_12K/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2258f37c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:57:30.976241Z",
     "iopub.status.busy": "2025-04-11T14:57:30.975417Z",
     "iopub.status.idle": "2025-04-11T14:57:30.980071Z",
     "shell.execute_reply": "2025-04-11T14:57:30.979155Z"
    },
    "papermill": {
     "duration": 0.009567,
     "end_time": "2025-04-11T14:57:30.981683",
     "exception": false,
     "start_time": "2025-04-11T14:57:30.972116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd1c0df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:57:30.988336Z",
     "iopub.status.busy": "2025-04-11T14:57:30.988015Z",
     "iopub.status.idle": "2025-04-11T14:57:30.992281Z",
     "shell.execute_reply": "2025-04-11T14:57:30.991365Z"
    },
    "papermill": {
     "duration": 0.009197,
     "end_time": "2025-04-11T14:57:30.993802",
     "exception": false,
     "start_time": "2025-04-11T14:57:30.984605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3896c6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:57:30.999818Z",
     "iopub.status.busy": "2025-04-11T14:57:30.999455Z",
     "iopub.status.idle": "2025-04-11T14:57:31.003829Z",
     "shell.execute_reply": "2025-04-11T14:57:31.002949Z"
    },
    "papermill": {
     "duration": 0.009329,
     "end_time": "2025-04-11T14:57:31.005603",
     "exception": false,
     "start_time": "2025-04-11T14:57:30.996274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb3e6bfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:57:31.011767Z",
     "iopub.status.busy": "2025-04-11T14:57:31.011456Z",
     "iopub.status.idle": "2025-04-11T14:57:31.015503Z",
     "shell.execute_reply": "2025-04-11T14:57:31.014715Z"
    },
    "papermill": {
     "duration": 0.00882,
     "end_time": "2025-04-11T14:57:31.017151",
     "exception": false,
     "start_time": "2025-04-11T14:57:31.008331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pytorch-lightning torchvision\n",
    "#!pip install torch-lr-finder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcfe3fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:57:31.023744Z",
     "iopub.status.busy": "2025-04-11T14:57:31.023406Z",
     "iopub.status.idle": "2025-04-11T14:57:48.419412Z",
     "shell.execute_reply": "2025-04-11T14:57:48.418477Z"
    },
    "papermill": {
     "duration": 17.401529,
     "end_time": "2025-04-11T14:57:48.421403",
     "exception": false,
     "start_time": "2025-04-11T14:57:31.019874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms #To manage dataset\n",
    "from torch.utils.data import DataLoader, Subset #To load and transform data\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger # As pytorch.lightning allows direct logging into wandb\n",
    "#from sklearn.model_selection import StratifiedShuffleSplit '''Check with TAs'''\n",
    "\n",
    "class CNN(pl.LightningModule):\n",
    "    def __init__(self,config):\n",
    "        super().__init__() #using LightningModule to assign hyperparams\n",
    "        self.save_hyperparameters(ignore=[\"config\"])\n",
    "        self.config = config\n",
    "\n",
    "        self.final_ch, self.final_size = self.calc_output_dim(config)\n",
    "\n",
    "        self.build_nn(config)\n",
    "    \n",
    "    def build_nn(self,config):\n",
    "        self.conv_blk = nn.ModuleList()\n",
    "        input_ch = 3 #RGB images\n",
    "        current_filters = config.filter_base #Filter Number & Strategies from sweep config\n",
    "        for i in range(5): #Create five consecutive convolution blocks with configurable strategies\n",
    "            self.conv_blk.append(\n",
    "                nn.Conv2d(input_ch, current_filters, kernel_size = config.filter_size, padding = config.filter_size//2) #Use filter size from sweep config, padding = floor(0.5*filter)\n",
    "            )\n",
    "            self.conv_blk.append(self.actv(config.conv_actv))\n",
    "            self.conv_blk.append(nn.MaxPool2d(kernel_size = config.pool_size))#, padding = config.pool_size//2))\n",
    "            #Define organization logic for filters in subsequent layers from sweep config metric filter_org\n",
    "            if config.filter_org == \"double\":\n",
    "                input_ch = current_filters\n",
    "                current_filters *= 2 #Double number of filters\n",
    "            elif config.filter_org == \"halve\":\n",
    "                input_ch = current_filters\n",
    "                current_filters = max(8, current_filters//2) #Ensuring a minimum of 8 filters\n",
    "            else: #No filter strategies\n",
    "                input_ch = current_filters\n",
    "          \n",
    "        self.dense = nn.Sequential(\n",
    "              nn.Linear(self.final_ch*self.final_size**2, config.dense_neurons),\n",
    "              self.actv(config.dense_actv),\n",
    "              nn.Dropout(config.dropout),\n",
    "              nn.Linear(config.dense_neurons, 10)\n",
    "          )\n",
    "\n",
    "    #Calculate what the dimensions for the dense layer inputs would turn out to be\n",
    "    def calc_output_dim(self,config):\n",
    "          with torch.no_grad():\n",
    "            dummy = torch.randn(1, 3, 224, 224)\n",
    "            input_ch = 3\n",
    "            current_filters = config.filter_base\n",
    "            spatial_size =224\n",
    "\n",
    "            for i in range(5):\n",
    "                conv = nn.Conv2d(\n",
    "                    input_ch, \n",
    "                    current_filters,\n",
    "                    kernel_size=config.filter_size,\n",
    "                    padding=config.filter_size//2\n",
    "                )\n",
    "                dummy = conv(dummy)\n",
    "                dummy = self.actv(config.conv_actv)(dummy)\n",
    "\n",
    "                dummy = F.max_pool2d(dummy, kernel_size = config.pool_size)\n",
    "                spatial_size = spatial_size // config.pool_size\n",
    "                #Error handling due to multiple errors lol\n",
    "                if spatial_size<1:\n",
    "                  raise ValueError(\n",
    "                      f\"Pool Size {config.pool_size} wrong for 5 convs\"\n",
    "                      f\"Max allowed: {224**(1/5):.0f}\"\n",
    "                  )\n",
    "\n",
    "                # Update filter organization\n",
    "                if config.filter_org == \"double\":\n",
    "                    input_ch = current_filters\n",
    "                    current_filters *= 2\n",
    "                elif config.filter_org == \"halve\":\n",
    "                    input_ch = current_filters\n",
    "                    current_filters = max(8, current_filters // 2)\n",
    "                else:\n",
    "                    input_ch = current_filters\n",
    "            print(dummy.shape[1], dummy.shape[2])        \n",
    "            return dummy.shape[1], dummy.shape[2]\n",
    "    def actv(self,name): #Choosing activation func\n",
    "        actv={\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"gelu\": nn.GELU(),\n",
    "            \"silu\": nn.SiLU(),\n",
    "            \"mish\": nn.Mish()\n",
    "        }\n",
    "        return actv[name.lower()]\n",
    "\n",
    "    def forward(self,x): #Explicit Lightning Module Method Forward\n",
    "        for layer in self.conv_blk:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.size(0), -1) #Flatten\n",
    "        return self.dense(x) #Invoke Dense layers\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"train_loss\",loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat,y)\n",
    "        acc = (y_hat.argmax(dim=1) == y).float().mean() #Mean fractional accuracy\n",
    "        self.log(\"val_loss\",loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "        return {\"val_loss\":loss, \"val_acc\":acc}\n",
    "\n",
    "    def configure_optimizers(self): #Another pl method. We use Adam optim\n",
    "        return torch.optim.Adam(self.parameters(), lr = self.config.eta) #have to use self.hparams ,if used, as referring config outside the __init__\n",
    "\n",
    "class DataManager(pl.LightningModule):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transform = self.tfms()\n",
    "\n",
    "    def tfms(self): #Preprocess input data. Add (Augment) data to make model robust\n",
    "        base_transform = [\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = [0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "        ]\n",
    "        if self.config.data_augmentation==True:\n",
    "            train_transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(15),\n",
    "                tranforms.ColorJitter(brightness = 0.2, contrast = 0.2, saturation = 0.2),\n",
    "                *base_transform\n",
    "            ])\n",
    "        else:\n",
    "            train_transform = transforms.Compose(base_transform)\n",
    "        \n",
    "        return {\n",
    "            \"train\": train_transform,\n",
    "            \"val\": transforms.Compose(base_transform),\n",
    "            \"test\": transforms.Compose(base_transform)\n",
    "        }\n",
    "\n",
    "    def data_setup(self, stage=None):\n",
    "        full_data = datasets.ImageFolder(root=\"data/train\", transform=self.transform[\"train\"])\n",
    "        #Implementing a random 80-20 train-val split\n",
    "        idx = list(range(len(full_data)))\n",
    "        np.random.seed(42) \n",
    "        np.random.shuffle(idx)\n",
    "        split = int(np.floor(0.8*size)) \n",
    "        train_idx = idx[:split]\n",
    "        val_idx = idx[split:]\n",
    "\n",
    "        self.train_data = Subset(full_data, train_idx)\n",
    "        self.val_data = Subset(val_data, val_idx)\n",
    "        self.test_data = datasets.ImageFolder(\n",
    "            root = \"data/test\",\n",
    "            \n",
    "        )\n",
    "    def train_loader(self):\n",
    "        return DataLoader(self.train_data, batch_size = self.config.batch_size, shuffle=True)\n",
    "    def val_loader(self):\n",
    "        return DataLoader(self.val_data, batch_size = self.config.batch_size, shuffle=True)\n",
    "    def test_loader(self):\n",
    "        return DataLoader(self.test_data, batch_size = self.config.batch_size, shuffle=True)\n",
    "\n",
    "#Define Configuration for param sweep\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\":\"val_acc\", \"goal\":\"maximize\"},\n",
    "    \"parameters\":{\n",
    "        \"filter_base\":{\"values\":[32,64]},\n",
    "        \"filter_size\":{\"values\":[3,5,7]},\n",
    "        \"filter_org\":{\"values\":[\"same\",\"double\",\"halve\"]},\n",
    "        \"conv_actv\":{\"values\":[\"relu\",\"gelu\",\"silu\",\"mish\"]},\n",
    "        \"dense_actv\":{\"values\":[\"relu\",\"gelu\"]},\n",
    "        \"dense_neurons\":{\"values\":[1024,2048,4096]},\n",
    "        \"data_augmentation\":{\"values\":[True,False]},\n",
    "        \"batch_norm\":{\"values\":[True,False]},\n",
    "        \"dropout\":{\"values\":[0.2,0.3]},\n",
    "        \"eta\":{\"min\":0.0001, \"max\":0.01, \"distribution\":\"log_uniform\"},\n",
    "        \"batch_size\":{\"values\":[64,128]}\n",
    "    },\n",
    "    \"early_terminate\":{\n",
    "        \"type\":\"hyperband\",\n",
    "        \"min_iter\": 3,\n",
    "        \"eta\": 2\n",
    "    }\n",
    "}\n",
    "def train_sweep():\n",
    "    \n",
    "    run = wandb.init(reinit=True, settings=wandb.Settings(start_method=\"thread\"))\n",
    "    try:\n",
    "        config = wandb.config\n",
    "        data_manager = DataManager(config)\n",
    "        model = CNN(config)\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs = 10,\n",
    "            logger = WandbLogger(),\n",
    "            accelerator = \"auto\",\n",
    "            enable_checkpointing = False,\n",
    "            deterministic = True\n",
    "        )\n",
    "        trainer.fit(model,data_manager)\n",
    "    except:\n",
    "        print(f\"Error in Training:{e}\")\n",
    "        run.finish(exit_code=1)\n",
    "    finally:\n",
    "        run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dda7e8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:57:48.427368Z",
     "iopub.status.busy": "2025-04-11T14:57:48.426863Z",
     "iopub.status.idle": "2025-04-11T14:57:48.430962Z",
     "shell.execute_reply": "2025-04-11T14:57:48.430129Z"
    },
    "papermill": {
     "duration": 0.008563,
     "end_time": "2025-04-11T14:57:48.432369",
     "exception": false,
     "start_time": "2025-04-11T14:57:48.423806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sweep_id = wandb.sweep(sweep_config, project = \"DA6401_A2\")\n",
    "#wandb.agent(sweep_id, function=train_sweep, count = 10)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7065602,
     "sourceId": 11298830,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31.13141,
   "end_time": "2025-04-11T14:57:52.030707",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-11T14:57:20.899297",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
